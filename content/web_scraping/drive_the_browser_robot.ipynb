{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "370a2fe7-649a-49ad-a6c0-f39e05f00ccf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Drive the Browser, Robot\n",
    "\n",
    "## That's an order. Not a request.\n",
    "\n",
    "The days of simple web sites built from plain-old HTML and CSS seem like a distant memory.\n",
    "\n",
    "Today, a growing number of sites use Javascript to dynamically add functionality *and* content to a page.\n",
    "\n",
    "Perhaps you're staring at a simple table of data on a government website and thinking: *This looks like an easy scrape!*\n",
    "\n",
    "Think again. \n",
    "\n",
    "Often, the data you see in a web browser is not actually present in the HTML of the page, but written into the page *after it has loaded* in your browser.\n",
    "\n",
    "> *Confused? That's natural. Check [this](website_personalities.ipynb) out. We'll wait...*\n",
    "\n",
    "In other words, [what you see is NOT what you get](wysiwyg_scraping.ipynb).\n",
    "\n",
    "That fact of modern life on the web can dramatically complicate the task of web scraping, especially if there's no [JSON API](../apis/README.ipynb) lurking under the hood that can allow you to [skip the scraping](skip_scraping_cheat.ipynb).\n",
    "\n",
    "Modern web pages are often just a collection of \"hooks\" with little of the most interesting content embedded in the source code. Instead, Javascript dynamically generates the content using logic and/or secondary sources of data such as a [JSON API](../apis/README.ipynb).\n",
    "\n",
    "In some cases, this lets us [avoid web scraping](skip_scraping_cheat.ipynb). We can simply grab the JSON, making the job much easier.\n",
    "\n",
    "In other cases, it's not so simple. Add into this mix a gaggle of other [website idiosyncracies](website_personalities.ipynb), and the traditional way of scraping (using simple tools such as `requests` and `BeautifulSoup`) becomes far more difficult or downright impossible.\n",
    "\n",
    "In such cases, it's often much easier to switch tactics and use a browser-automation tool to drive Chrome or Firefox to harvest files, data, etc.\n",
    "\n",
    "**You're essentially automating a human workflow: Open browser. Do stuff.**\n",
    "\n",
    "This approach is a bit mind-bendy and more complex than plain-old `requests`, but it's quite handy when tackling a difficult web scrape.\n",
    "\n",
    "Many programming languages have browser automation tools. In Python, two of the most popular are [Selenium](https://selenium-python.readthedocs.io/index.html) and the newer kid on the block: [Playwright](https://playwright.dev/python/).\n",
    "\n",
    "We'll use Playwright in this tutorial since it simplifies some of the initial setup.\n",
    "\n",
    "> **IMPORTANT**: This tutorial must be run locally on your own machine. It won't work on GitHub Codespaces or in JupyterLite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba69b15-10d2-4342-bc64-875e68b4e773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "If you haven't already done so, clone the [data-journalism-notebooks GitHub repository](https://github.com/stanfordjournalism/data-journalism-notebooks), either using VS Code or the command line:\n",
    "\n",
    "```bash\n",
    "# Here's how to use plain old git to clone on the command line\n",
    "git clone git@github.com:stanfordjournalism/data-journalism-notebooks.git\n",
    "```\n",
    "\n",
    "You can install `playwright` using `pip` or `pipenv`. We've included `playwright` in the `Pipfile` for this repo, so plain-old `pipenv install` should have you covered.\n",
    "\n",
    "```bash\n",
    "# On the command line, navigate to the code repo,\n",
    "# replacing \"path/to\" with a real path on your machine.\n",
    "cd path/to/data-journalism-notebooks\n",
    "pipenv install # will include playwright and some other goodies\n",
    "```\n",
    "\n",
    "Make sure you have the Google Chromium browser installed on your machine, though note you can also use Firefox and other browsers with `playwright`.\n",
    "\n",
    "`playwright` requires browser drivers to interact with web browsers installed on your machine.\n",
    "\n",
    "Run the following command to install the browser drivers:\n",
    "        \n",
    "```bash\n",
    "# On the command line, navigate to our repo\n",
    "cd path/to/data-journalism-notebooks\n",
    "# Activate the virtual environment (where playwright was installed)\n",
    "pipenv shell\n",
    "# Install the drivers\n",
    "playwright install\n",
    "```\n",
    "\n",
    "This command will download and install the necessary drivers for Chromium, Firefox, and WebKit browsers.\n",
    "\n",
    "> Note: If you encounter any permission issues while installing the library or browser drivers, try running the command as an administrator: `sudo playwright install` on Mac/Linux systems.\n",
    "\n",
    "Verify the installation by executing the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b028aeb-5017-49dc-9a4d-7c5a08a2218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.sync_api import sync_playwright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebde9c6-cbea-4573-bb81-0d3f9b225530",
   "metadata": {},
   "source": [
    "If the import statement executes without any errors, the `playwright` library is successfully installed and ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531968ab-4d3e-4532-b0fa-0ad10787e083",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Robot, go to example.com\n",
    "\n",
    "Launch a browser instance using `playwright` and navigate to <https://example.com>.\n",
    "\n",
    "### **Important**\n",
    "\n",
    "This code is more complex than if we were working in a simple Python script (with a `.py` extension).\n",
    "\n",
    "Because we're working in Jupyter Lab, which has its own [\"event loop\"](https://medium.com/@dpzhcmy/running-asynchronous-code-in-jupyter-notebooks-managing-event-loops-b9696a596ce4), we have to use Playwright in so-called `async` mode.\n",
    "\n",
    "In practical terms, that means you have to prepend the `await` keyword on most invocations of `playwright` classes, methods, etc.\n",
    "\n",
    "> *See [Hidden Life of Objects](../classes_and_oop/hidden_life_of_objects.ipynb) if you're unfamiliar with terms such as classes and methods. Check out [Async IO in Python: A Complete Walkthrough](https://realpython.com/async-io-python/) for background on asynchronous Python.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c07ced-f071-4483-b067-34b31f2fe4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "pw = await async_playwright().start()\n",
    "# make the browser visible instead of running in \"headless\" mode\n",
    "browser = await pw.chromium.launch(headless=False)\n",
    "page = await browser.new_page()\n",
    "await page.goto(\"https://example.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30243abf-3ac0-4a41-9397-80c47a6561cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = await page.query_selector('h1')\n",
    "text = await h1.inner_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced6ac8b-ce62-454a-80f0-a429c0d3a2b0",
   "metadata": {},
   "source": [
    "Congratulations!! You just made the robot do your bidding.\n",
    "\n",
    "It's important to dismiss the robot when you're done by the way, if for no other reason than avoiding a boatload of open browser tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d45853-ca14-4764-9620-41658dec7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "await browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602480dc-e402-487a-a2a3-bc4e1da93b67",
   "metadata": {},
   "source": [
    "## Do harder things Robot\n",
    "\n",
    "Ok, so that was a nice warm-up. Let's put `playwright` through its paces on a more challenging website.\n",
    "\n",
    "This time we'll work with the Oklahoma Court Search index.\n",
    "\n",
    "Technically, it's possible to scrape this site with plain-old `requests` and `BeautifulSoup`, and in fact we do just that in the Big Local News [court-scraper](https://github.com/biglocalnews/court-scraper) project.\n",
    "\n",
    "But the site is sufficiently complex that `playwright` is a justifiable alternative.\n",
    "\n",
    "Here's the Oklahoma [Case Docket Search page](https://oscn.net/dockets/Search.aspx). \n",
    "\n",
    "![Oklahoma court search](../files/ok_courts_search.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8816b327-4012-4f3f-98bf-fa31546129c4",
   "metadata": {},
   "source": [
    "The page contains a number of forms, allowing you to search for docket information by:\n",
    "    \n",
    "- County / court\n",
    "- Case number\n",
    "- Name of parties to the case\n",
    "- Case date range (not pictured above; scroll down the page)\n",
    "\n",
    "## Test the search\n",
    "\n",
    "Before writing any code, you should always spend some time exploring a site from the perspective of a normal user. \n",
    "\n",
    "As an example, let's try hunting down the docket info for a case between an Oklahoma resident named Scott Sapulpa and the Gannett news company. Sapulpa won a $25 million award from Gannett in February 2024. Here's the [AP story](https://apnews.com/article/oklahoma-newspaper-defamation-racist-comments-7a97e443a35097fa25617106ea20bafe) on the judgement.\n",
    "\n",
    "![ok man wins 5 million from gannett](../files/ok_man_wins_5m_from_gannett.png)\n",
    "\n",
    "We don't have the case number, but the story contains enough details for us to hunt down the docket information based on the plaintiff's name and the county where the case was filed.\n",
    "\n",
    "Navigate to the [Case Docket Search page](https://oscn.net/dockets/Search.aspx) and fill in the form fields.\n",
    "\n",
    "First select `Muskogee County District Court` from the court selection menu.\n",
    "\n",
    "![ok search muskogee count](../files/ok_court_select_muskogee.png)\n",
    "\n",
    "Next, fill in the plaintiff's last name (`Sapulpa`) and first name (`Scott`).\n",
    "\n",
    "![ok search sapulpa case](../files/ok_search_sapulpa.png)\n",
    "\n",
    "Now click the `Go` button, making sure to use the one in the `Search by Party` section (there are `Go` buttons in each section).\n",
    "\n",
    "This should display a page of cases, including *Sapulpa v. Gannett*.\n",
    "\n",
    "![ok search results](../files/ok_court_search_results.png)\n",
    "\n",
    "Lastly, if you click through the record, you'll find oodles of information related to the case, from parties involved in the case to important events and even downloadable case filings.\n",
    "\n",
    "![ok court case detail page](../files/ok_case_detail_page.png)\n",
    "\n",
    "## Automate the Search\n",
    "\n",
    "So we have a feel for the search system. \n",
    "\n",
    "Better yet, we've created a roadmap of the steps we'll need to follow when using `playwright` to automate the browser:\n",
    "\n",
    "- Go to case search page\n",
    "- Fill in court / county field\n",
    "- Fill in last and first name fields\n",
    "- Click `Go` under `Search by Party`\n",
    "- Locate the case on search results page\n",
    "- Click on case to view detailed docket information\n",
    "\n",
    "### Go to search page\n",
    "\n",
    "Let's grab some starter code from the earlier `example.com` scrape, with a few tweaks:\n",
    "\n",
    "- Skip the import line since we already did that in an earlier notebook cell\n",
    "- Update the URL in the `page.goto(...)` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335c19c-9adb-4894-97f1-68c703524414",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = await async_playwright().start()\n",
    "browser = await pw.chromium.launch(headless=False)\n",
    "page = await browser.new_page()\n",
    "await page.goto(\"https://oscn.net/dockets/Search.aspx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b000fbe-cae7-4e1f-836e-19a63e86dcdf",
   "metadata": {},
   "source": [
    "### Select the county\n",
    "\n",
    "Did the page open for you? Great.\n",
    "\n",
    "Now we need to pinpoint the `County or Court` search menu and select Muskogee County.\n",
    "\n",
    "If we examine the HTML, we can see this is a `<select>` tag  and it has an associated `<label>`.\n",
    "\n",
    "![ok court field with html](../files/ok_court_field_with_html.png)\n",
    "\n",
    "`playwright` provides tons of different methods to interact with elements on a web page. \n",
    "\n",
    "For example, you can [locate an element by its label](https://playwright.dev/python/docs/locators#locate-by-label).\n",
    "\n",
    "In our case, that label is `County or Court:` (note the trailing colon `:`).\n",
    "\n",
    "Below, we create a `locator` using the field's label, and then select the court option by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b716a-7f9a-4947-9223-7298416bd06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = page.get_by_label(\"County or Court:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039bd97-dba4-473a-8802-67b2466567db",
   "metadata": {},
   "outputs": [],
   "source": [
    "await locator.select_option(\"Muskogee County District Court\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c259e55-732d-47ce-b94b-28eb17265908",
   "metadata": {},
   "source": [
    "### Fill the name fields\n",
    "\n",
    "Next up, we need to fill in those name fields. \n",
    "\n",
    "Once again, we should inspect the source code to get our bearings.\n",
    "\n",
    "![OK court search name fields html](../files/ok_search_name_field_html.png)\n",
    "\n",
    "We can see that these are standard `input` fields. They also have labels, so let's try using the `get_by_label` method again, this time with the [fill](https://playwright.dev/python/docs/api/class-locator#locator-fill) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62388765-13f4-4c02-9e28-f8a9bc4fa582",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.get_by_label(\"Last name:\").fill('Sapulpa')\n",
    "await page.get_by_label(\"First Name:\").fill('Scott')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1856d-b3c8-4d26-a12c-d995622684e2",
   "metadata": {},
   "source": [
    "### Click Go\n",
    "\n",
    "We're now ready to click. You know the routine. Inspect the HTML to locate the button. \n",
    "\n",
    "Then use `playwright` to select and click the button.\n",
    "\n",
    "**The one hitch is that our page has more than one `Go` button** (one per search section).\n",
    "\n",
    "We want to click the second button at the end of the `Search by Party` section.\n",
    "\n",
    "Let's grab all the buttons and pluck out the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c0eff-ef9c-4ead-9606-ce70704f2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "buttons = await page.query_selector_all('input.submit[type=\"submit\"]')\n",
    "# Grab the second button and click\n",
    "await buttons[1].click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef58218-feff-4182-8776-568f9b9fef71",
   "metadata": {},
   "source": [
    "### Locate the detail page and click through\n",
    "\n",
    "Hopefully you now see the search results page we described earlier.\n",
    "\n",
    "The last step in this process involves locating the `Scott Sapulpa V. Gannett CO. INC.` row and clicking through to the case information page.\n",
    "\n",
    "Once again, let's pry open the hood on the web page.\n",
    "\n",
    "![ok sapulpa search results html](../files/ok_sapulpa_case_results_html.png)\n",
    "\n",
    "We can see there's a table data (`td`) tag that contains the link (`a` tag) to our case.\n",
    "\n",
    "Let's select the link using the case name text and trigger a click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476c07b-dc5c-4d2e-b748-fda4c055127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = page.get_by_text(\"SCOTT  SAPULPA V. GANNETT CO. INC.\")\n",
    "await link.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7842d-2b13-4fdf-9267-b2e1fc5a2054",
   "metadata": {},
   "source": [
    "## Time to celebrate\n",
    "\n",
    "If the case information page opened, congratulations!! It's time to bust out the champagne and party!!\n",
    "\n",
    "You've now subjected the machine to your will. The case detail page is ready and waiting for you to harvest data and documents. We'll leave that as an exercise (see `Code Challenges` below).\n",
    "\n",
    "Hopefully you're feeling the rush of excitement that comes with this form of web scraping. \n",
    "\n",
    "We won't rain on the party excessively by reminding you that scraping -- using browser automation or otherwise -- should always be an option of last resort.\n",
    "\n",
    "But when all else fails, it sure can help sidestep bureaucratic and technical hurdles.\n",
    "\n",
    "One last technical reminder: Once you're done admiring the case information page, make sure to close the browser. The robot deserves a break once in a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094acaf-009b-4fd5-b70d-04273f0bb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "await browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd139ed1-b073-41b4-b4ff-9c406ce9d4e9",
   "metadata": {},
   "source": [
    "## Code Challenges\n",
    "\n",
    "If you're hooked on scraping, try your hand at the below code challenges to get some more reps.\n",
    "\n",
    "- Update the notebook to extract metadata from the case information page (e.g. party names, lawyers, etc.)\n",
    "- Update the notebook to download documents from the case information page\n",
    "- Update the notebook to extract case information and documents from *all* cases listed on the search results page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
